////////////////////////////////////////////////////////////////////
// A simple mixed discrete continuous MDP for a single Mars Rover.
// A Rover must traverse a 2D region and take pictures within the
// bounding boxes of designated picture points denoted by nonfluents
// within time constraints (e.g., Martian daylight).  Note that this 
// models continuous time explicitly since there is only one rover.
//
// The continuous state (x,y,t) consists of robot position (x,y) and time t.
// The discrete state consists of whether each picture-point has been taken. 
// The action consists of movements (dx,dy) or the snapping of a picture
// without moving (state-action constraints enforce this exclusion).
// A reward is gained for snapping a picture within the bounding box
// of a picture point -- reward can only be obtained for a picture once.
//
// The goal here is to take as many high-value pictures (within their
// designated radii) as possible within the time constraints.
//
// I can provide a proper version of this domain using circles for 
// picture-points and Euclidean distance for time updating on movement.
//
// Motivated by:
//
//   Bresina, J. L.; Dearden, R.; Meuleau, N.; Ramkrishnan, S.;
//   Smith, D. E.; and Washington, R. 2002. Planning under continuous
//   time and resource uncertainty: A challenge for AI. UAI 2002.
//
// Author: Scott Sanner (ssanner@gmail.com)
////////////////////////////////////////////////////////////////////
domain simple_mars_rover {
  
	requirements = { 
		concurrent,           // x and y directions move independently and simultaneously
		reward-deterministic, // this domain does not use a stochastic reward
		intermediate-nodes,   // this domain uses intermediate pvariable nodes
		constrained-state     // this domain uses state constraints
	};

	types {
		picture-point : object;
	};

	pvariables { 
    		  		
    	// Problem constants
    	MAX_TIME : { non-fluent, real, default = 12.0 };
    		  		
		// Rover constants
		MOVE_VARIANCE_MULT : { non-fluent, real, default = 0.5 };
		
		// Each picture occurs in a different place and awards a different value
		PICT_XPOS(picture-point)   : { non-fluent, real, default = 0.0 };
		PICT_YPOS(picture-point)   : { non-fluent, real, default = 0.0 };
		PICT_VALUE(picture-point)  : { non-fluent, real, default = 1.0 };
		PICT_ERROR_ALLOW(picture-point) : { non-fluent, real, default = 0.5 };
		
		// Rover coordinates
		xPos : { state-fluent, real, default = 0.0 };
		yPos : { state-fluent, real, default = 0.0 };
		time : { state-fluent, real, default = 0.0 };
		picTaken(picture-point) : { state-fluent, bool, default = false };

		// Rover actions -- constraints enforce that a rover cannot snap a picture
		//                  and move simultaneously
		xMove       : { action-fluent, real, default = 0.0 };
		yMove       : { action-fluent, real, default = 0.0 };
		snapPicture : { action-fluent, bool, default = false };
		
	};
	
	cpfs {

		// Update rover coordinates based on movement, we assume surface 
		// of Mars has no coordinate constraints.  Can add if needed.
		
		xPos' = xPos + xMove + Normal(0.0, MOVE_VARIANCE_MULT*abs[xMove]);
		yPos' = yPos + yMove + Normal(0.0, MOVE_VARIANCE_MULT*abs[yMove]);
		
		// We assume taking a picture requires 1/4 hour and movement takes
		// the Manhattan distance time (assuming units are meters and speed 
		// is 1 m/hour).  Euclidean distance would be more plausible, but
		// we need to add elementary functions like sqrt into RDDL for this.
		// Even an absolute value would simplify things here as well.
		time' = if (snapPicture)
				then (time + 0.25)
				else (time + abs[xMove] + abs[yMove]);
		


		
		picTaken'(?p) = picTaken(?p) |
					[snapPicture ^ (time <= MAX_TIME) 
						 ^ (abs[xPos - PICT_XPOS(?p)] <= PICT_ERROR_ALLOW(?p))
						 ^ (abs[yPos - PICT_YPOS(?p)] <= PICT_ERROR_ALLOW(?p))];
	};
  
	// We get a reward for any picture ?p taken within picture box error bounds 
	// and the time limit on *this* time step (if picTaken(?p) transitioned from 
	// false to true we increment reward by PICT_VALUE(?p)).
	reward = sum_{?p : picture-point} [ (~picTaken(?p) ^ picTaken'(?p)) * PICT_VALUE(?p) ];
	
	action-preconditions {

		// Cannot snap a picture and move at the same time
		(~snapPicture) | ((xMove == 0.0) ^ (yMove == 0.0));
	};
}
